"""
è©•ä¼°æ¨¡çµ„ (Evaluation Module)
æä¾›æ¨¡å‹è©•ä¼°æŒ‡æ¨™è¨ˆç®—èˆ‡é æ¸¬çµæœè¦–è¦ºåŒ–åŠŸèƒ½
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
from typing import Tuple, List, Optional
from pathlib import Path
from tqdm import tqdm


def evaluate_model(
    model: nn.Module,
    data_loader: DataLoader,
    device: torch.device,
    criterion: Optional[nn.Module] = None
) -> Tuple[float, float, np.ndarray, np.ndarray]:
    """
    è©•ä¼°æ¨¡å‹åœ¨çµ¦å®šè³‡æ–™é›†ä¸Šçš„è¡¨ç¾
    
    Args:
        model: è¦è©•ä¼°çš„æ¨¡å‹
        data_loader: è³‡æ–™è¼‰å…¥å™¨
        device: é‹ç®—è£ç½®
        criterion: æå¤±å‡½æ•¸ (å¯é¸)
        
    Returns:
        (æå¤±, æº–ç¢ºç‡, æ‰€æœ‰é æ¸¬, æ‰€æœ‰æ¨™ç±¤)
    """
    model.eval()
    
    total_loss = 0.0
    all_predictions = []
    all_labels = []
    
    with torch.no_grad():
        for images, labels in tqdm(data_loader, desc='è©•ä¼°ä¸­'):
            images = images.to(device)
            labels = labels.to(device)
            
            # å‰å‘å‚³æ’­
            outputs = model(images)
            
            # è¨ˆç®—æå¤±
            if criterion is not None:
                loss = criterion(outputs, labels)
                total_loss += loss.item() * images.size(0)
            
            # å–å¾—é æ¸¬çµæœ
            _, predicted = torch.max(outputs, 1)
            
            # æ”¶é›†é æ¸¬èˆ‡æ¨™ç±¤
            all_predictions.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    
    # è¨ˆç®—å¹³å‡æå¤±èˆ‡æº–ç¢ºç‡
    avg_loss = total_loss / len(data_loader.dataset) if criterion else 0.0
    all_predictions = np.array(all_predictions)
    all_labels = np.array(all_labels)
    accuracy = 100.0 * (all_predictions == all_labels).sum() / len(all_labels)
    
    return avg_loss, accuracy, all_predictions, all_labels


def plot_confusion_matrix(
    y_true: np.ndarray,
    y_pred: np.ndarray,
    class_names: List[str],
    save_path: Optional[str] = None,
    figsize: Tuple[int, int] = (10, 8)
) -> None:
    """
    ç¹ªè£½æ··æ·†çŸ©é™£ (Confusion Matrix)
    
    Args:
        y_true: çœŸå¯¦æ¨™ç±¤
        y_pred: é æ¸¬æ¨™ç±¤
        class_names: é¡åˆ¥åç¨±åˆ—è¡¨
        save_path: å„²å­˜è·¯å¾‘ (å¯é¸)
        figsize: åœ–è¡¨å°ºå¯¸
    """
    # è¨ˆç®—æ··æ·†çŸ©é™£
    cm = confusion_matrix(y_true, y_pred)
    
    # ç¹ªè£½ç†±åŠ›åœ–
    plt.figure(figsize=figsize)
    sns.heatmap(
        cm,
        annot=True,
        fmt='d',
        cmap='Blues',
        xticklabels=class_names,
        yticklabels=class_names,
        cbar_kws={'label': 'æ¨£æœ¬æ•¸é‡'}
    )
    
    plt.title('æ··æ·†çŸ©é™£ (Confusion Matrix)', fontsize=16, fontweight='bold', pad=20)
    plt.xlabel('é æ¸¬æ¨™ç±¤', fontsize=12)
    plt.ylabel('çœŸå¯¦æ¨™ç±¤', fontsize=12)
    plt.tight_layout()
    
    if save_path:
        Path(save_path).parent.mkdir(parents=True, exist_ok=True)
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f'ğŸ“Š æ··æ·†çŸ©é™£å·²å„²å­˜è‡³ {save_path}')
    
    plt.show()


def print_classification_report(
    y_true: np.ndarray,
    y_pred: np.ndarray,
    class_names: List[str]
) -> None:
    """
    è¼¸å‡ºåˆ†é¡å ±å‘Š (Precision, Recall, F1-Score)
    
    Args:
        y_true: çœŸå¯¦æ¨™ç±¤
        y_pred: é æ¸¬æ¨™ç±¤
        class_names: é¡åˆ¥åç¨±åˆ—è¡¨
    """
    print('\n' + '=' * 70)
    print('åˆ†é¡å ±å‘Š (Classification Report)')
    print('=' * 70)
    
    report = classification_report(
        y_true,
        y_pred,
        target_names=class_names,
        digits=4
    )
    print(report)


def visualize_predictions(
    model: nn.Module,
    data_loader: DataLoader,
    device: torch.device,
    class_names: List[str],
    num_samples: int = 16,
    save_path: Optional[str] = None
) -> None:
    """
    è¦–è¦ºåŒ–æ¨¡å‹é æ¸¬çµæœ
    
    Args:
        model: è¨“ç·´å¥½çš„æ¨¡å‹
        data_loader: è³‡æ–™è¼‰å…¥å™¨
        device: é‹ç®—è£ç½®
        class_names: é¡åˆ¥åç¨±åˆ—è¡¨
        num_samples: è¦é¡¯ç¤ºçš„æ¨£æœ¬æ•¸é‡
        save_path: å„²å­˜è·¯å¾‘ (å¯é¸)
    """
    model.eval()
    
    # å–å¾—ä¸€æ‰¹è³‡æ–™
    images, labels = next(iter(data_loader))
    images = images[:num_samples].to(device)
    labels = labels[:num_samples]
    
    # é€²è¡Œé æ¸¬
    with torch.no_grad():
        outputs = model(images)
        probabilities = torch.softmax(outputs, dim=1)
        confidences, predictions = torch.max(probabilities, 1)
    
    # å°‡è³‡æ–™ç§»å› CPU
    images = images.cpu()
    predictions = predictions.cpu().numpy()
    confidences = confidences.cpu().numpy()
    labels = labels.numpy()
    
    # ç¹ªè£½çµæœ
    rows = int(np.sqrt(num_samples))
    cols = int(np.ceil(num_samples / rows))
    
    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2.5, rows * 2.5))
    axes = axes.flatten() if num_samples > 1 else [axes]
    
    for idx in range(num_samples):
        ax = axes[idx]
        
        # é¡¯ç¤ºå½±åƒ (å»é™¤æ­£è¦åŒ–)
        img = images[idx].squeeze()
        mean, std = 0.1307, 0.3081
        img = img * std + mean  # åæ­£è¦åŒ–
        img = torch.clamp(img, 0, 1)
        
        ax.imshow(img, cmap='gray')
        ax.axis('off')
        
        # è¨­å®šæ¨™é¡Œ (æ­£ç¢º: ç¶ è‰²ï¼ŒéŒ¯èª¤: ç´…è‰²)
        true_label = class_names[labels[idx]]
        pred_label = class_names[predictions[idx]]
        confidence = confidences[idx] * 100
        
        is_correct = labels[idx] == predictions[idx]
        color = 'green' if is_correct else 'red'
        
        title = f'çœŸå¯¦: {true_label}\né æ¸¬: {pred_label} ({confidence:.1f}%)'
        ax.set_title(title, fontsize=10, color=color, fontweight='bold')
    
    # éš±è—å¤šé¤˜çš„å­åœ–
    for idx in range(num_samples, len(axes)):
        axes[idx].axis('off')
    
    plt.suptitle('æ¨¡å‹é æ¸¬çµæœè¦–è¦ºåŒ–', fontsize=16, fontweight='bold', y=1.02)
    plt.tight_layout()
    
    if save_path:
        Path(save_path).parent.mkdir(parents=True, exist_ok=True)
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f'ğŸ–¼ï¸  é æ¸¬è¦–è¦ºåŒ–å·²å„²å­˜è‡³ {save_path}')
    
    plt.show()


def visualize_misclassified(
    model: nn.Module,
    data_loader: DataLoader,
    device: torch.device,
    class_names: List[str],
    num_samples: int = 16,
    save_path: Optional[str] = None
) -> None:
    """
    è¦–è¦ºåŒ–æ¨¡å‹é æ¸¬éŒ¯èª¤çš„æ¨£æœ¬
    
    Args:
        model: è¨“ç·´å¥½çš„æ¨¡å‹
        data_loader: è³‡æ–™è¼‰å…¥å™¨
        device: é‹ç®—è£ç½®
        class_names: é¡åˆ¥åç¨±åˆ—è¡¨
        num_samples: è¦é¡¯ç¤ºçš„æ¨£æœ¬æ•¸é‡
        save_path: å„²å­˜è·¯å¾‘ (å¯é¸)
    """
    model.eval()
    
    misclassified_images = []
    misclassified_preds = []
    misclassified_labels = []
    misclassified_confs = []
    
    # æ”¶é›†é æ¸¬éŒ¯èª¤çš„æ¨£æœ¬
    with torch.no_grad():
        for images, labels in data_loader:
            images = images.to(device)
            labels = labels.to(device)
            
            outputs = model(images)
            probabilities = torch.softmax(outputs, dim=1)
            confidences, predictions = torch.max(probabilities, 1)
            
            # æ‰¾å‡ºé æ¸¬éŒ¯èª¤çš„æ¨£æœ¬
            incorrect_mask = predictions != labels
            
            if incorrect_mask.sum() > 0:
                misclassified_images.append(images[incorrect_mask].cpu())
                misclassified_preds.append(predictions[incorrect_mask].cpu())
                misclassified_labels.append(labels[incorrect_mask].cpu())
                misclassified_confs.append(confidences[incorrect_mask].cpu())
            
            # æ”¶é›†è¶³å¤ çš„æ¨£æœ¬å¾Œåœæ­¢
            if sum(img.size(0) for img in misclassified_images) >= num_samples:
                break
    
    if len(misclassified_images) == 0:
        print('ğŸ‰ æ²’æœ‰æ‰¾åˆ°é æ¸¬éŒ¯èª¤çš„æ¨£æœ¬!')
        return
    
    # åˆä½µæ¨£æœ¬
    misclassified_images = torch.cat(misclassified_images)[:num_samples]
    misclassified_preds = torch.cat(misclassified_preds)[:num_samples]
    misclassified_labels = torch.cat(misclassified_labels)[:num_samples]
    misclassified_confs = torch.cat(misclassified_confs)[:num_samples]
    
    # ç¹ªè£½çµæœ
    rows = int(np.sqrt(num_samples))
    cols = int(np.ceil(num_samples / rows))
    
    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2.5, rows * 2.5))
    axes = axes.flatten() if num_samples > 1 else [axes]
    
    for idx in range(min(num_samples, len(misclassified_images))):
        ax = axes[idx]
        
        # é¡¯ç¤ºå½±åƒ
        img = misclassified_images[idx].squeeze()
        mean, std = 0.1307, 0.3081
        img = img * std + mean
        img = torch.clamp(img, 0, 1)
        
        ax.imshow(img, cmap='gray')
        ax.axis('off')
        
        # è¨­å®šæ¨™é¡Œ
        true_label = class_names[misclassified_labels[idx]]
        pred_label = class_names[misclassified_preds[idx]]
        confidence = misclassified_confs[idx] * 100
        
        title = f'çœŸå¯¦: {true_label}\né æ¸¬: {pred_label} ({confidence:.1f}%)'
        ax.set_title(title, fontsize=10, color='red', fontweight='bold')
    
    # éš±è—å¤šé¤˜çš„å­åœ–
    for idx in range(len(misclassified_images), len(axes)):
        axes[idx].axis('off')
    
    plt.suptitle('é æ¸¬éŒ¯èª¤çš„æ¨£æœ¬', fontsize=16, fontweight='bold', y=1.02)
    plt.tight_layout()
    
    if save_path:
        Path(save_path).parent.mkdir(parents=True, exist_ok=True)
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f'ğŸ–¼ï¸  éŒ¯èª¤æ¡ˆä¾‹è¦–è¦ºåŒ–å·²å„²å­˜è‡³ {save_path}')
    
    plt.show()


if __name__ == '__main__':
    print('âœ… è©•ä¼°æ¨¡çµ„è¼‰å…¥æˆåŠŸ!')
    print('   å¯ç”¨å‡½å¼:')
    print('   - evaluate_model(): è©•ä¼°æ¨¡å‹è¡¨ç¾')
    print('   - plot_confusion_matrix(): ç¹ªè£½æ··æ·†çŸ©é™£')
    print('   - print_classification_report(): è¼¸å‡ºåˆ†é¡å ±å‘Š')
    print('   - visualize_predictions(): è¦–è¦ºåŒ–é æ¸¬çµæœ')
    print('   -visualize_misclassified(): è¦–è¦ºåŒ–é æ¸¬éŒ¯èª¤çš„æ¨£æœ¬')
