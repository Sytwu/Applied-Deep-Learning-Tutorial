"""
æ¨¡å‹æ¶æ§‹æ¨¡çµ„ (Model Architecture Module)
å®šç¾© CNN (Convolutional Neural Network) æ¨¡å‹ç”¨æ–¼ CIFAR-10 å½±åƒåˆ†é¡

å­¸ç”Ÿä»»å‹™:
- å¯¦ä½œ ConvBlock çš„ __init__ æ–¹æ³•ä¾†å»ºç«‹å·ç©å€å¡Š
- å¯¦ä½œ CNN çš„ __init__ æ–¹æ³•ä¾†çµ„åˆå¤šå€‹å·ç©å€å¡Š
- ç†è§£ CNN çš„å‰å‘å‚³æ’­æµç¨‹
"""

import torch
import torch.nn as nn
from typing import List, Optional


class ConvBlock(nn.Module):
    """
    å·ç©å€å¡Š (Convolutional Block)
    æ¨™æº–çµ„æˆ: Conv2d â†’ BatchNorm2d â†’ ReLU â†’ MaxPool2d
    """
    
    def __init__(
        self,
        in_channels: int,
        out_channels: int,
        kernel_size: int = 3,
        padding: int = 1,
        pool: bool = True
    ):
        """
        åˆå§‹åŒ–å·ç©å€å¡Š
        
        Args:
            in_channels: è¼¸å…¥é€šé“æ•¸
            out_channels: è¼¸å‡ºé€šé“æ•¸
            kernel_size: å·ç©æ ¸å¤§å° (é è¨­ 3x3)
            padding: Padding å¤§å° (é è¨­ 1)
            pool: æ˜¯å¦åŒ…å« MaxPooling (é è¨­ True)
        """
        super(ConvBlock, self).__init__()
        
        # ========================================
        # TODO: å­¸ç”Ÿå¯¦ä½œå€ - å»ºç«‹å·ç©å€å¡Š
        # ========================================
        # å»ºç«‹ä¸€å€‹å·ç©å€å¡Šï¼ŒåŒ…å«ä»¥ä¸‹å±¤ï¼ˆæŒ‰é †åºï¼‰:
        #
        # 1. Conv2d: å·ç©å±¤
        #    - ä½¿ç”¨: nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding)
        #    - åŠŸèƒ½: æå–ç©ºé–“ç‰¹å¾µ
        #    - ç¯„ä¾‹: Conv2d(3, 64, 3, padding=1) 
        #            è¼¸å…¥ (3, 32, 32) â†’ è¼¸å‡º (64, 32, 32)
        #
        # 2. BatchNorm2d: æ‰¹æ¬¡æ­£è¦åŒ–
        #    - ä½¿ç”¨: nn.BatchNorm2d(out_channels)
        #    - åŠŸèƒ½: ç©©å®šè¨“ç·´ï¼ŒåŠ é€Ÿæ”¶æ–‚
        #    - æ³¨æ„: æ­£è¦åŒ–çš„é€šé“æ•¸æ˜¯è¼¸å‡ºé€šé“æ•¸
        #
        # 3. ReLU: æ¿€æ´»å‡½æ•¸
        #    - ä½¿ç”¨: nn.ReLU(inplace=True)
        #    - åŠŸèƒ½: å¼•å…¥éç·šæ€§
        #    - inplace=True å¯ç¯€çœè¨˜æ†¶é«”
        #
        # 4. MaxPool2d: æœ€å¤§æ± åŒ– (å¦‚æœ pool=True)
        #    - ä½¿ç”¨: nn.MaxPool2d(kernel_size=2, stride=2)
        #    - åŠŸèƒ½: é™ä½ç©ºé–“ç¶­åº¦ï¼Œæå–é¡¯è‘—ç‰¹å¾µ
        #    - æ•ˆæœ: (H, W) â†’ (H/2, W/2)
        #    - ç¯„ä¾‹: (64, 32, 32) â†’ (64, 16, 16)
        #
        # å¯¦ä½œæ–¹å¼ 1 (æ¨è–¦): ä½¿ç”¨åˆ—è¡¨ + nn.Sequential
        # layers = []
        # layers.append(nn.Conv2d(...))
        # layers.append(nn.BatchNorm2d(...))
        # layers.append(nn.ReLU(...))
        # if pool:
        #     layers.append(nn.MaxPool2d(...))
        # self.block = nn.Sequential(*layers)
        #
        # å¯¦ä½œæ–¹å¼ 2: åˆ†åˆ¥å®šç¾©
        # self.conv = nn.Conv2d(...)
        # self.bn = nn.BatchNorm2d(...)
        # self.relu = nn.ReLU(...)
        # self.pool = nn.MaxPool2d(...) if pool else nn.Identity()
        # ========================================
        
        # TODO: åœ¨é€™è£¡å»ºç«‹ self.block
        # ç¯„ä¾‹çµæ§‹:
        # self.block = nn.Sequential(
        #     nn.Conv2d(...),
        #     nn.BatchNorm2d(...),
        #     nn.ReLU(...),
        #     nn.MaxPool2d(...) if pool else ...
        # )
        
        raise NotImplementedError("å­¸ç”Ÿéœ€è¦å¯¦ä½œ ConvBlock.__init__")
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘å‚³æ’­ (å·²æä¾›ï¼Œç„¡éœ€ä¿®æ”¹)
        
        Args:
            x: è¼¸å…¥ Tensor
        
        Returns:
            è™•ç†å¾Œçš„ Tensor
        """
        return self.block(x)


class CNN(nn.Module):
    """
    å·ç©ç¥ç¶“ç¶²è·¯ (Convolutional Neural Network) æ¨¡å‹
    
    æ¶æ§‹è¨­è¨ˆ:
    è¼¸å…¥ (3, 32, 32) RGB å½±åƒ
      â†“
    ConvBlock 1: 3 â†’ 64 é€šé“, 32Ã—32 â†’ 16Ã—16
      â†“
    ConvBlock 2: 64 â†’ 128 é€šé“, 16Ã—16 â†’ 8Ã—8
      â†“
    ConvBlock 3: 128 â†’ 256 é€šé“, 8Ã—8 â†’ 4Ã—4
      â†“
    ConvBlock 4: 256 â†’ 512 é€šé“, 4Ã—4 â†’ 2Ã—2
      â†“
    Global Average Pooling: (512, 2, 2) â†’ (512, 1, 1)
      â†“
    Flatten: (512, 1, 1) â†’ (512,)
      â†“
    Dropout + Linear: (512,) â†’ (10,)
    """
    
    def __init__(
        self,
        in_channels: int = 3,  # RGB å½±åƒ
        num_classes: int = 10,  # CIFAR-10 æœ‰ 10 å€‹é¡åˆ¥
        base_channels: int = 64,
        dropout_rate: float = 0.5
    ):
        """
        åˆå§‹åŒ– CNN æ¨¡å‹
        
        Args:
            in_channels: è¼¸å…¥é€šé“æ•¸ (RGB=3, ç°éš=1)
            num_classes: è¼¸å‡ºé¡åˆ¥æ•¸é‡
            base_channels: åŸºç¤é€šé“æ•¸ (ç¬¬ä¸€å±¤çš„è¼¸å‡ºé€šé“)
            dropout_rate: Dropout æ¯”ç‡
        """
        super(CNN, self).__init__()
        
        self.in_channels = in_channels
        self.num_classes = num_classes
        
        # ========================================
        # TODO: å­¸ç”Ÿå¯¦ä½œå€ - å»ºç«‹ç‰¹å¾µæå–å™¨
        # ========================================
        # ä½¿ç”¨ nn.Sequential çµ„åˆ 4 å€‹ ConvBlock
        #
        # é€šé“æ•¸è®ŠåŒ–è¦å¾‹: æ¯å±¤é€šé“æ•¸ç¿»å€
        # Block 1: in_channels (3) â†’ base_channels (64)
        # Block 2: base_channels (64) â†’ base_channels * 2 (128)
        # Block 3: base_channels * 2 (128) â†’ base_channels * 4 (256)
        # Block 4: base_channels * 4 (256) â†’ base_channels * 8 (512)
        #
        # ç©ºé–“å°ºå¯¸è®ŠåŒ– (å› ç‚º MaxPool):
        # Block 1: 32Ã—32 â†’ 16Ã—16
        # Block 2: 16Ã—16 â†’ 8Ã—8
        # Block 3: 8Ã—8 â†’ 4Ã—4
        # Block 4: 4Ã—4 â†’ 2Ã—2
        #
        # å¯¦ä½œç¯„ä¾‹:
        # self.features = nn.Sequential(
        #     ConvBlock(in_channels, base_channels, pool=True),
        #     ConvBlock(base_channels, base_channels * 2, pool=True),
        #     ConvBlock(...),  # ä½ ä¾†å¡«
        #     ConvBlock(...)   # ä½ ä¾†å¡«
        # )
        # ========================================
        
        # TODO: å»ºç«‹ self.features (ç‰¹å¾µæå–å™¨)
        self.features = None  # æ›¿æ›ç‚ºä½ çš„å¯¦ä½œ
        
        # ========================================
        # TODO: å­¸ç”Ÿå¯¦ä½œå€ - å»ºç«‹å…¨åŸŸå¹³å‡æ± åŒ–
        # ========================================
        # Global Average Pooling (GAP):
        # - å°‡ (batch, 512, 2, 2) è½‰ç‚º (batch, 512, 1, 1)
        # - å°æ¯å€‹ channel çš„æ•´å€‹ç©ºé–“ç¶­åº¦å–å¹³å‡
        # - ä½¿ç”¨: nn.AdaptiveAvgPool2d((1, 1))
        # - å„ªå‹¢: åƒæ•¸æ›´å°‘ï¼Œå°è¼¸å…¥å°ºå¯¸æ›´éˆæ´»
        # ========================================
        
        # TODO: å»ºç«‹ self.global_avg_pool
        self.global_avg_pool = None  # æ›¿æ›ç‚ºä½ çš„å¯¦ä½œ
        
        # ========================================
        # TODO: å­¸ç”Ÿå¯¦ä½œå€ - å»ºç«‹åˆ†é¡å™¨
        # ========================================
        # åˆ†é¡å™¨åŒ…å«:
        # 1. Dropout: nn.Dropout(dropout_rate)
        #    - é˜²æ­¢éæ“¬åˆ
        #    - è¨“ç·´æ™‚éš¨æ©Ÿä¸Ÿæ£„ 50% çš„ç¥ç¶“å…ƒ
        #
        # 2. Linear: nn.Linear(base_channels * 8, num_classes)
        #    - æœ€çµ‚çš„åˆ†é¡å±¤
        #    - è¼¸å…¥: 512 ç¶­ç‰¹å¾µå‘é‡
        #    - è¼¸å‡º: 10 å€‹é¡åˆ¥çš„åˆ†æ•¸
        #
        # ä½¿ç”¨ nn.Sequential çµ„åˆ:
        # self.classifier = nn.Sequential(
        #     nn.Dropout(dropout_rate),
        #     nn.Linear(base_channels * 8, num_classes)
        # )
        # ========================================
        
        # TODO: å»ºç«‹ self.classifier
        self.classifier = None  # æ›¿æ›ç‚ºä½ çš„å¯¦ä½œ
        
        # æª¢æŸ¥æ˜¯å¦å®Œæˆå¯¦ä½œ
        if self.features is None or self.global_avg_pool is None or self.classifier is None:
            raise NotImplementedError("å­¸ç”Ÿéœ€è¦å®Œæˆ CNN.__init__ çš„å¯¦ä½œ")
        
        # åˆå§‹åŒ–æ¬Šé‡ (å·²æä¾›)
        self._initialize_weights()
    
    def _initialize_weights(self) -> None:
        """
        åˆå§‹åŒ–æ¨¡å‹æ¬Šé‡ (å·²æä¾›ï¼Œç„¡éœ€ä¿®æ”¹)
        ä½¿ç”¨ Kaiming åˆå§‹åŒ–ï¼Œé©åˆ ReLU æ¿€æ´»å‡½æ•¸
        """
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘å‚³æ’­ (å·²æä¾›ï¼Œç„¡éœ€ä¿®æ”¹)
        
        Args:
            x: è¼¸å…¥ Tensorï¼Œå½¢ç‹€ç‚º (batch_size, 3, 32, 32)
            
        Returns:
            è¼¸å‡º Tensorï¼Œå½¢ç‹€ç‚º (batch_size, num_classes)
        
        Tensor å½¢ç‹€è®ŠåŒ–:
            è¼¸å…¥:           (batch_size, 3, 32, 32)
            Conv Block 1:   (batch_size, 64, 16, 16)
            Conv Block 2:   (batch_size, 128, 8, 8)
            Conv Block 3:   (batch_size, 256, 4, 4)
            Conv Block 4:   (batch_size, 512, 2, 2)
            Global Avg Pool: (batch_size, 512, 1, 1)
            Flatten:        (batch_size, 512)
            Classifier:     (batch_size, 10)
        """
        # ç‰¹å¾µæå–
        x = self.features(x)  # (batch, 3, 32, 32) â†’ (batch, 512, 2, 2)
        
        # å…¨åŸŸå¹³å‡æ± åŒ–
        x = self.global_avg_pool(x)  # (batch, 512, 2, 2) â†’ (batch, 512, 1, 1)
        
        # å±•å¹³
        x = torch.flatten(x, 1)  # (batch, 512, 1, 1) â†’ (batch, 512)
        
        # åˆ†é¡
        x = self.classifier(x)  # (batch, 512) â†’ (batch, 10)
        
        return x
    
    def get_num_parameters(self) -> int:
        """
        è¨ˆç®—æ¨¡å‹ç¸½åƒæ•¸é‡
        
        Returns:
            æ¨¡å‹ç¸½åƒæ•¸æ•¸é‡
        """
        return sum(p.numel() for p in self.parameters() if p.requires_grad)


def create_cnn_model(
    in_channels: int = 3,
    num_classes: int = 10,
    base_channels: int = 64,
    dropout_rate: float = 0.5
) -> CNN:
    """
    ä¾¿æ·å‡½å¼ï¼šå‰µå»º CNN æ¨¡å‹
    
    Args:
        in_channels: è¼¸å…¥é€šé“æ•¸
        num_classes: è¼¸å‡ºé¡åˆ¥æ•¸é‡
        base_channels: åŸºç¤é€šé“æ•¸
        dropout_rate: Dropout æ¯”ç‡
        
    Returns:
        CNN æ¨¡å‹å¯¦ä¾‹
    """
    model = CNN(
        in_channels=in_channels,
        num_classes=num_classes,
        base_channels=base_channels,
        dropout_rate=dropout_rate
    )
    
    print(f'âœ… å»ºç«‹ CNN æ¨¡å‹æˆåŠŸ!')
    print(f'   åŸºç¤é€šé“æ•¸: {base_channels}')
    print(f'   ç¸½åƒæ•¸é‡: {model.get_num_parameters():,}')
    
    return model


if __name__ == '__main__':
    # æ¸¬è©¦æ¨¡å‹
    print('ğŸ§ª æ¸¬è©¦ CNN æ¨¡å‹...\n')
    
    try:
        model = create_cnn_model()
        
        # å»ºç«‹æ¸¬è©¦è¼¸å…¥ (CIFAR-10 æ ¼å¼: RGB 32x32)
        batch_size = 4
        test_input = torch.randn(batch_size, 3, 32, 32)
        
        # å‰å‘å‚³æ’­
        output = model(test_input)
        
        print(f'\nğŸ“Š æ¨¡å‹æ¸¬è©¦çµæœ:')
        print(f'   è¼¸å…¥å½¢ç‹€: {test_input.shape}')
        print(f'   è¼¸å‡ºå½¢ç‹€: {output.shape}')
        print(f'   é æœŸè¼¸å‡ºå½¢ç‹€: ({batch_size}, 10)')
        
        # é©—è­‰è¼¸å‡ºå½¢ç‹€
        assert output.shape == (batch_size, 10), 'è¼¸å‡ºå½¢ç‹€ä¸æ­£ç¢º!'
        print(f'\nâœ… æ¨¡å‹æ¸¬è©¦é€šé!')
        
    except NotImplementedError as e:
        print(f'\nâš ï¸  {e}')
        print('\nè«‹å®Œæˆä»¥ä¸‹ TODO å€å¡Š:')
        print('1. ConvBlock.__init__() - å»ºç«‹å·ç©å€å¡Š')
        print('2. CNN.__init__() - å»ºç«‹ç‰¹å¾µæå–å™¨ã€å…¨åŸŸå¹³å‡æ± åŒ–ã€åˆ†é¡å™¨')
