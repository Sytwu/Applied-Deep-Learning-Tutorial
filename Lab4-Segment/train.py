"""
è¨“ç·´å™¨æ¨¡çµ„ (Trainer Module)
å°è£è¨“ç·´èˆ‡é©—è­‰æµç¨‹çš„ Trainer é¡åˆ¥
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from typing import Dict, List, Optional, Tuple
from tqdm import tqdm
from pathlib import Path

from utils import AverageMeter, save_checkpoint


class Trainer:
    """
    è¨“ç·´å™¨é¡åˆ¥
    è² è²¬æ¨¡å‹çš„è¨“ç·´ã€é©—è­‰ã€å­¸ç¿’ç‡èª¿åº¦èˆ‡æ¨¡å‹å„²å­˜
    """
    
    def __init__(
        self,
        model: nn.Module,
        train_loader: DataLoader,
        val_loader: DataLoader,
        criterion: nn.Module,
        optimizer: optim.Optimizer,
        device: torch.device,
        save_dir: str = './checkpoints',
        scheduler: Optional[optim.lr_scheduler._LRScheduler] = None
    ):
        """
        åˆå§‹åŒ–è¨“ç·´å™¨
        
        Args:
            model: è¦è¨“ç·´çš„æ¨¡å‹
            train_loader: è¨“ç·´é›† DataLoader
            val_loader: é©—è­‰é›† DataLoader
            criterion: æå¤±å‡½æ•¸
            optimizer: å„ªåŒ–å™¨
            device: é‹ç®—è£ç½®
            save_dir: æ¨¡å‹å„²å­˜ç›®éŒ„
            scheduler: å­¸ç¿’ç‡èª¿åº¦å™¨ (å¯é¸)
        """
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.criterion = criterion
        self.optimizer = optimizer
        self.device = device
        self.scheduler = scheduler
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)
        
        # è¨˜éŒ„è¨“ç·´æ­·å²
        self.train_losses = []
        self.val_losses = []
        self.train_accs = []
        self.val_accs = []
        
        # æœ€ä½³æŒ‡æ¨™
        self.best_val_acc = 0.0
        self.best_epoch = 0
    
    def train_one_epoch(self, epoch: int) -> Tuple[float, float]:
        """
        è¨“ç·´ä¸€å€‹ epoch
        
        Args:
            epoch: ç•¶å‰ epoch ç·¨è™Ÿ
            
        Returns:
            (å¹³å‡æå¤±, å¹³å‡æº–ç¢ºç‡)
        """
        self.model.train()  # è¨­å®šç‚ºè¨“ç·´æ¨¡å¼
        
        losses = AverageMeter()
        accs = AverageMeter()
        
        # ä½¿ç”¨ tqdm é¡¯ç¤ºè¨“ç·´é€²åº¦
        pbar = tqdm(self.train_loader, desc=f'Epoch {epoch} [Train]')
        
        for images, labels in pbar:
            # å°‡è³‡æ–™ç§»è‡³æŒ‡å®šè£ç½®
            images = images.to(self.device)
            labels = labels.to(self.device)
            
            batch_size = images.size(0)
            
            # TODO: Student Implementation
            # è«‹å®Œæˆä»¥ä¸‹è¨“ç·´æ­¥é©Ÿ:
            # 1. æ¸…ç©ºæ¢¯åº¦
            # 2. å‰å‘å‚³æ’­
            # 3. è¨ˆç®—æå¤±
            # 4. åå‘å‚³æ’­
            # 5. æ›´æ–°æ¬Šé‡
            
            # æç¤º: ä½¿ç”¨ optimizer.zero_grad(), model(), criterion(), loss.backward(), optimizer.step()
            
            # 1. æ¸…ç©ºæ¢¯åº¦
            self.optimizer.zero_grad()
            
            # 2. å‰å‘å‚³æ’­
            outputs = self.model(images)
            
            # 3. è¨ˆç®—æå¤±
            loss = self.criterion(outputs, labels)
            
            # 4. åå‘å‚³æ’­
            loss.backward()
            
            # 5. æ›´æ–°æ¬Šé‡
            self.optimizer.step()
            
            # è¨ˆç®—æº–ç¢ºç‡
            _, predicted = torch.max(outputs, 1)
            correct = (predicted == labels).sum().item()
            acc = 100.0 * correct / batch_size
            
            # æ›´æ–°çµ±è¨ˆ
            losses.update(loss.item(), batch_size)
            accs.update(acc, batch_size)
            
            # æ›´æ–°é€²åº¦æ¢é¡¯ç¤º
            pbar.set_postfix({
                'Loss': f'{losses.avg:.4f}',
                'Acc': f'{accs.avg:.2f}%'
            })
        
        return losses.avg, accs.avg
    
    def validate(self, epoch: int) -> Tuple[float, float]:
        """
        åœ¨é©—è­‰é›†ä¸Šè©•ä¼°æ¨¡å‹
        
        Args:
            epoch: ç•¶å‰ epoch ç·¨è™Ÿ
            
        Returns:
            (å¹³å‡æå¤±, å¹³å‡æº–ç¢ºç‡)
        """
        self.model.eval()  # è¨­å®šç‚ºè©•ä¼°æ¨¡å¼
        
        losses = AverageMeter()
        accs = AverageMeter()
        
        pbar = tqdm(self.val_loader, desc=f'Epoch {epoch} [Val]')
        
        with torch.no_grad():  # é©—è­‰æ™‚ä¸éœ€è¦è¨ˆç®—æ¢¯åº¦
            for images, labels in pbar:
                images = images.to(self.device)
                labels = labels.to(self.device)
                
                batch_size = images.size(0)
                
                # å‰å‘å‚³æ’­
                outputs = self.model(images)
                loss = self.criterion(outputs, labels)
                
                # è¨ˆç®—æº–ç¢ºç‡
                _, predicted = torch.max(outputs, 1)
                correct = (predicted == labels).sum().item()
                acc = 100.0 * correct / batch_size
                
                # æ›´æ–°çµ±è¨ˆ
                losses.update(loss.item(), batch_size)
                accs.update(acc, batch_size)
                
                # æ›´æ–°é€²åº¦æ¢é¡¯ç¤º
                pbar.set_postfix({
                    'Loss': f'{losses.avg:.4f}',
                    'Acc': f'{accs.avg:.2f}%'
                })
        
        return losses.avg, accs.avg
    
    def train(self, num_epochs: int) -> Dict[str, List[float]]:
        """
        åŸ·è¡Œå®Œæ•´è¨“ç·´æµç¨‹
        
        Args:
            num_epochs: è¨“ç·´è¼ªæ•¸
            
        Returns:
            åŒ…å«è¨“ç·´æ­·å²çš„å­—å…¸
        """
        print(f'\nğŸš€ é–‹å§‹è¨“ç·´ï¼Œå…± {num_epochs} å€‹ Epochs\n')
        print('=' * 70)
        
        for epoch in range(1, num_epochs + 1):
            # è¨“ç·´ä¸€å€‹ epoch
            train_loss, train_acc = self.train_one_epoch(epoch)
            
            # é©—è­‰
            val_loss, val_acc = self.validate(epoch)
            
            # è¨˜éŒ„æ­·å²
            self.train_losses.append(train_loss)
            self.val_losses.append(val_loss)
            self.train_accs.append(train_acc)
            self.val_accs.append(val_acc)
            
            # å­¸ç¿’ç‡èª¿åº¦
            if self.scheduler is not None:
                self.scheduler.step()
            
            # é¡¯ç¤º epoch ç¸½çµ
            print(f'\nEpoch {epoch}/{num_epochs} Summary:')
            print(f'  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%')
            print(f'  Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%')
            
            # å„²å­˜æœ€ä½³æ¨¡å‹
            is_best = val_acc > self.best_val_acc
            if is_best:
                self.best_val_acc = val_acc
                self.best_epoch = epoch
                print(f'  ğŸ‰ æ–°çš„æœ€ä½³é©—è­‰æº–ç¢ºç‡: {val_acc:.2f}%')
            
            # å„²å­˜æª¢æŸ¥é»
            save_path = self.save_dir / f'checkpoint_epoch_{epoch}.pth'
            save_checkpoint(
                model=self.model,
                optimizer=self.optimizer,
                epoch=epoch,
                best_metric=self.best_val_acc,
                save_path=str(save_path),
                is_best=is_best
            )
            
            print('=' * 70)
        
        print(f'\nâœ… è¨“ç·´å®Œæˆ!')
        print(f'   æœ€ä½³é©—è­‰æº–ç¢ºç‡: {self.best_val_acc:.2f}% (Epoch {self.best_epoch})')
        
        return {
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'train_accs': self.train_accs,
            'val_accs': self.val_accs,
            'best_val_acc': self.best_val_acc,
            'best_epoch': self.best_epoch
        }
