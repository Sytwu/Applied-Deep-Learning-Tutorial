"""
è¨“ç·´å™¨æ¨¡çµ„ (Trainer Module)
å°è£è¨“ç·´èˆ‡é©—è­‰æµç¨‹çš„ Trainer é¡åˆ¥
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from typing import Dict, List, Optional, Tuple
from tqdm import tqdm
from pathlib import Path

from utils import AverageMeter, save_checkpoint


class Trainer:
    """
    è¨“ç·´å™¨é¡åˆ¥
    è² è²¬æ¨¡å‹çš„è¨“ç·´ã€é©—è­‰ã€å­¸ç¿’ç‡èª¿åº¦èˆ‡æ¨¡å‹å„²å­˜
    """
    
    def __init__(
        self,
        model: nn.Module,
        train_loader: DataLoader,
        val_loader: DataLoader,
        criterion: nn.Module,
        optimizer: optim.Optimizer,
        device: torch.device,
        save_dir: str = './checkpoints',
        scheduler: Optional[optim.lr_scheduler._LRScheduler] = None
    ):
        """
        åˆå§‹åŒ–è¨“ç·´å™¨
        
        Args:
            model: è¦è¨“ç·´çš„æ¨¡å‹
            train_loader: è¨“ç·´é›† DataLoader
            val_loader: é©—è­‰é›† DataLoader
            criterion: æå¤±å‡½æ•¸
            optimizer: å„ªåŒ–å™¨
            device: é‹ç®—è£ç½®
            save_dir: æ¨¡å‹å„²å­˜ç›®éŒ„
            scheduler: å­¸ç¿’ç‡èª¿åº¦å™¨ (å¯é¸)
        """
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.criterion = criterion
        self.optimizer = optimizer
        self.device = device
        self.scheduler = scheduler
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)
        
        # è¨˜éŒ„è¨“ç·´æ­·å²
        self.train_losses = []
        self.val_losses = []
        self.train_accs = []
        self.val_accs = []
        
        # æœ€ä½³æŒ‡æ¨™
        self.best_val_acc = 0.0
        self.best_epoch = 0
    
    def train_one_epoch(self, epoch: int) -> Tuple[float, float]:
        """
        è¨“ç·´ä¸€å€‹ epoch
        
        Args:
            epoch: ç•¶å‰ epoch ç·¨è™Ÿ
            
        Returns:
            (å¹³å‡æå¤±, å¹³å‡æº–ç¢ºç‡)
        """
        self.model.train()  # è¨­å®šç‚ºè¨“ç·´æ¨¡å¼
        
        losses = AverageMeter()
        accs = AverageMeter()
        
        # ä½¿ç”¨ tqdm é¡¯ç¤ºè¨“ç·´é€²åº¦
        pbar = tqdm(self.train_loader, desc=f'Epoch {epoch} [Train]')
        
        for images, labels in pbar:
            # å°‡è³‡æ–™ç§»è‡³æŒ‡å®šè£ç½®
            images = images.to(self.device)
            labels = labels.to(self.device)
            
            batch_size = images.size(0)
            
            # ========================================
            # TODO: å­¸ç”Ÿå¯¦ä½œå€ - è¨“ç·´æ­¥é©Ÿ
            # ========================================
            # è«‹å®Œæˆä»¥ä¸‹ 5 å€‹è¨“ç·´æ­¥é©Ÿ:
            #
            # æ­¥é©Ÿ 1: æ¸…ç©ºæ¢¯åº¦
            #   - æ¯æ¬¡è¨“ç·´å‰å¿…é ˆæ¸…ç©ºä¹‹å‰ç´¯ç©çš„æ¢¯åº¦
            #   - ä½¿ç”¨: self.optimizer.zero_grad()
            #
            # æ­¥é©Ÿ 2: å‰å‘å‚³æ’­
            #   - å°‡å½±åƒé€šéæ¨¡å‹å¾—åˆ°è¼¸å‡º
            #   - ä½¿ç”¨: outputs = self.model(images)
            #   - è¼¸å‡ºå½¢ç‹€: (batch_size, 10)
            #
            # æ­¥é©Ÿ 3: è¨ˆç®—æå¤±
            #   - æ¯”è¼ƒæ¨¡å‹è¼¸å‡ºèˆ‡çœŸå¯¦æ¨™ç±¤
            #   - ä½¿ç”¨: loss = self.criterion(outputs, labels)
            #   - criterion æ˜¯ CrossEntropyLoss
            #
            # æ­¥é©Ÿ 4: åå‘å‚³æ’­
            #   - è¨ˆç®—æå¤±å°å„åƒæ•¸çš„æ¢¯åº¦
            #   - ä½¿ç”¨: loss.backward()
            #
            # æ­¥é©Ÿ 5: æ›´æ–°æ¬Šé‡
            #   - æ ¹æ“šæ¢¯åº¦æ›´æ–°æ¨¡å‹åƒæ•¸
            #   - ä½¿ç”¨: self.optimizer.step()
            #
            # ç‚ºä»€éº¼éœ€è¦é€™ 5 å€‹æ­¥é©Ÿ?
            # - æ­¥é©Ÿ 1: é˜²æ­¢æ¢¯åº¦ç´¯ç©
            # - æ­¥é©Ÿ 2-3: è¨ˆç®—ç•¶å‰é æ¸¬èˆ‡çœŸå¯¦å€¼çš„å·®è·
            # - æ­¥é©Ÿ 4-5: æ ¹æ“šå·®è·èª¿æ•´æ¨¡å‹åƒæ•¸ï¼Œä½¿å…¶æ”¹é€²
            # ========================================
            
            # TODO: åœ¨é€™è£¡å¯¦ä½œä¸Šè¿° 5 å€‹æ­¥é©Ÿ
            # æ­¥é©Ÿ 1: ...
            # æ­¥é©Ÿ 2: ...
            # æ­¥é©Ÿ 3: ...
            # æ­¥é©Ÿ 4: ...
            # æ­¥é©Ÿ 5: ...
            
            raise NotImplementedError("å­¸ç”Ÿéœ€è¦å¯¦ä½œè¨“ç·´æ­¥é©Ÿ")
            
            # ä»¥ä¸‹ç¨‹å¼ç¢¼æœƒåœ¨å­¸ç”Ÿå®Œæˆ TODO å¾ŒåŸ·è¡Œ
            # (è«‹ç§»é™¤ä¸Šé¢çš„ raise NotImplementedError)
            
            # è¨ˆç®—æº–ç¢ºç‡
            _, predicted = torch.max(outputs, 1)
            correct = (predicted == labels).sum().item()
            acc = 100.0 * correct / batch_size
            
            # æ›´æ–°çµ±è¨ˆ
            losses.update(loss.item(), batch_size)
            accs.update(acc, batch_size)
            
            # æ›´æ–°é€²åº¦æ¢é¡¯ç¤º
            pbar.set_postfix({
                'Loss': f'{losses.avg:.4f}',
                'Acc': f'{accs.avg:.2f}%'
            })
        
        return losses.avg, accs.avg
    
    def validate(self, epoch: int) -> Tuple[float, float]:
        """
        åœ¨é©—è­‰é›†ä¸Šè©•ä¼°æ¨¡å‹
        
        Args:
            epoch: ç•¶å‰ epoch ç·¨è™Ÿ
            
        Returns:
            (å¹³å‡æå¤±, å¹³å‡æº–ç¢ºç‡)
        """
        self.model.eval()  # è¨­å®šç‚ºè©•ä¼°æ¨¡å¼
        
        losses = AverageMeter()
        accs = AverageMeter()
        
        pbar = tqdm(self.val_loader, desc=f'Epoch {epoch} [Val]')
        
        # ========================================
        # TODO: å­¸ç”Ÿå¯¦ä½œå€ - é©—è­‰è¿´åœˆ
        # ========================================
        # å¯¦ä½œé©—è­‰è¿´åœˆï¼Œèˆ‡è¨“ç·´è¿´åœˆé¡ä¼¼ä½†æœ‰å¹¾å€‹é—œéµå·®ç•°:
        #
        # é—œéµå·®ç•°:
        # 1. éœ€è¦ä½¿ç”¨ with torch.no_grad(): åŒ…ä½æ•´å€‹è¿´åœˆ
        #    - é€™æœƒåœç”¨æ¢¯åº¦è¨ˆç®—ï¼Œç¯€çœè¨˜æ†¶é«”èˆ‡è¨ˆç®—æ™‚é–“
        #    - é©—è­‰æ™‚ä¸éœ€è¦æ›´æ–°æ¨¡å‹ï¼Œæ‰€ä»¥ä¸éœ€è¦æ¢¯åº¦
        #
        # 2. ä¸éœ€è¦ä»¥ä¸‹æ­¥é©Ÿ (èˆ‡è¨“ç·´ä¸åŒ):
        #    - optimizer.zero_grad()  âŒ
        #    - loss.backward()        âŒ
        #    - optimizer.step()       âŒ
        #
        # éœ€è¦çš„æ­¥é©Ÿ:
        # 1. ä½¿ç”¨ with torch.no_grad(): é–‹å§‹
        # 2. è¿­ä»£ pbar: for images, labels in pbar:
        # 3. å°‡è³‡æ–™ç§»åˆ°è£ç½® (images.to(...), labels.to(...))
        # 4. å‰å‘å‚³æ’­: outputs = self.model(images)
        # 5. è¨ˆç®—æå¤±: loss = self.criterion(outputs, labels)
        # 6. è¨ˆç®—æº–ç¢ºç‡: torch.max(), æ¯”è¼ƒ predicted == labels
        # 7. æ›´æ–°çµ±è¨ˆ: losses.update(), accs.update()
        # 8. æ›´æ–°é€²åº¦æ¢: pbar.set_postfix()
        #
        # åƒè€ƒ train_one_epoch çš„çµæ§‹ï¼Œä½†è¨˜å¾—:
        # - æ•´å€‹è¿´åœˆè¦åœ¨ with torch.no_grad(): è£¡é¢
        # - ä¸è¦åå‘å‚³æ’­å’Œæ¢¯åº¦æ›´æ–°
        # ========================================
        
        # TODO: åœ¨é€™è£¡å¯¦ä½œé©—è­‰è¿´åœˆ
        
        raise NotImplementedError("å­¸ç”Ÿéœ€è¦å¯¦ä½œé©—è­‰è¿´åœˆ")
        
        return losses.avg, accs.avg
    
    def train(self, num_epochs: int) -> Dict[str, List[float]]:
        """
        åŸ·è¡Œå®Œæ•´è¨“ç·´æµç¨‹
        
        Args:
            num_epochs: è¨“ç·´è¼ªæ•¸
            
        Returns:
            åŒ…å«è¨“ç·´æ­·å²çš„å­—å…¸
        """
        print(f'\nğŸš€ é–‹å§‹è¨“ç·´ï¼Œå…± {num_epochs} å€‹ Epochs\n')
        print('=' * 70)
        
        for epoch in range(1, num_epochs + 1):
            # è¨“ç·´ä¸€å€‹ epoch
            train_loss, train_acc = self.train_one_epoch(epoch)
            
            # é©—è­‰
            val_loss, val_acc = self.validate(epoch)
            
            # è¨˜éŒ„æ­·å²
            self.train_losses.append(train_loss)
            self.val_losses.append(val_loss)
            self.train_accs.append(train_acc)
            self.val_accs.append(val_acc)
            
            # å­¸ç¿’ç‡èª¿åº¦
            if self.scheduler is not None:
                self.scheduler.step()
            
            # é¡¯ç¤º epoch ç¸½çµ
            print(f'\nEpoch {epoch}/{num_epochs} Summary:')
            print(f'  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%')
            print(f'  Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%')
            
            # å„²å­˜æœ€ä½³æ¨¡å‹
            is_best = val_acc > self.best_val_acc
            if is_best:
                self.best_val_acc = val_acc
                self.best_epoch = epoch
                print(f'  ğŸ‰ æ–°çš„æœ€ä½³é©—è­‰æº–ç¢ºç‡: {val_acc:.2f}%')
            
            # å„²å­˜æª¢æŸ¥é»
            save_path = self.save_dir / f'checkpoint_epoch_{epoch}.pth'
            save_checkpoint(
                model=self.model,
                optimizer=self.optimizer,
                epoch=epoch,
                best_metric=self.best_val_acc,
                save_path=str(save_path),
                is_best=is_best
            )
            
            print('=' * 70)
        
        print(f'\nâœ… è¨“ç·´å®Œæˆ!')
        print(f'   æœ€ä½³é©—è­‰æº–ç¢ºç‡: {self.best_val_acc:.2f}% (Epoch {self.best_epoch})')
        
        return {
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'train_accs': self.train_accs,
            'val_accs': self.val_accs,
            'best_val_acc': self.best_val_acc,
            'best_epoch': self.best_epoch
        }
